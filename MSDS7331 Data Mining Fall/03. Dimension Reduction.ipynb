{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sandbox calcs\n",
    "# import numpy as np\n",
    "# k = np.array([[37.1,-6.55],\n",
    "#               [-6.55,43.99]])\n",
    "# eigenvalues, eigenvectors = np.linalg.eig(k)\n",
    "# print eigenvectors, eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction with a Simple Dataset\n",
    "Here we are going to start with the iris dataset. This is a very simple dataset that is four dimensions. Details about this data are rampant on the web. \n",
    "- Here is a good explanation from UCI: https://archive.ics.uci.edu/ml/datasets/Iris \n",
    "- And even more details from Wikipedia: http://en.wikipedia.org/wiki/Iris_flower_data_set \n",
    "\n",
    "Let's get started. We will use scikit for this analysis, which has a built-in loading mechanism for the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets as ds\n",
    "\n",
    "iris = ds.load_iris() # wow that was simple to load up!\n",
    "\n",
    "print (iris['DESCR']) # a description of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      "sepal length (cm)    150 non-null float64\n",
      "sepal width (cm)     150 non-null float64\n",
      "petal length (cm)    150 non-null float64\n",
      "petal width (cm)     150 non-null float64\n",
      "target               150 non-null int32\n",
      "dtypes: float64(4), int32(1)\n",
      "memory usage: 5.4 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's convert it to a pandas data frame and visualize it\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "# add in the class targets and names\n",
    "df['target'] = iris.target.astype(np.int)\n",
    "print (df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fe68677f3902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "sns.pairplot(df, hue=\"target\", size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca: [[ 0.36158968 -0.08226889  0.85657211  0.35884393]\n",
      " [-0.65653988 -0.72971237  0.1757674   0.07470647]]\n",
      "lda: [[-0.81926852 -1.5478732   2.18494056  2.85385002]\n",
      " [ 0.03285975  2.15471106 -0.93024679  2.8060046 ]]\n"
     ]
    }
   ],
   "source": [
    "# now let's use PCA, and LDA to find the two \"best\" dimensions of this data\n",
    "# these are linear transforms to help project the features into something more understandable\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "target_names = iris.target_names\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit(X).transform(X) # fit data and then transform it\n",
    "\n",
    "lda = LDA(n_components=2)\n",
    "X_lda = lda.fit(X, y).transform(X) # fit data and then transform it\n",
    "\n",
    "# print the components\n",
    "\n",
    "print ('pca:', pca.components_)\n",
    "print ('lda:', lda.scalings_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function definition just formats the weights into readable strings\n",
    "# you can skip it without loss of generality to the Data Science content\n",
    "def get_feature_names_from_weights(weights, names):\n",
    "    tmp_array = []\n",
    "    for comp in weights:\n",
    "        tmp_string = ''\n",
    "        for fidx,f in enumerate(names):\n",
    "            if fidx>0 and comp[fidx]>=0:\n",
    "                tmp_string+='+'\n",
    "            tmp_string += '%.2f*%s ' % (comp[fidx],f[:-5])\n",
    "        tmp_array.append(tmp_string)\n",
    "    return tmp_array\n",
    "  \n",
    "# now let's get to the Data Analytics!\n",
    "pca_weight_strings = get_feature_names_from_weights(pca.components_, iris.feature_names) \n",
    "lda_weight_strings = get_feature_names_from_weights(lda.scalings_.T, iris.feature_names) \n",
    "\n",
    "# create some pandas dataframes from the transformed outputs\n",
    "df_pca = pd.DataFrame(X_pca,columns=[pca_weight_strings])\n",
    "df_lda = pd.DataFrame(X_lda,columns=[lda_weight_strings])\n",
    "\n",
    "from pandas.tools.plotting import scatter_plot\n",
    "\n",
    "# scatter plot the output, with the names crated from the weights\n",
    "ax = scatter_plot(df_pca, pca_weight_strings[0], pca_weight_strings[1], c=y, s=(y+2)*10)\n",
    "newfig = plt.figure()\n",
    "ax = scatter_plot(df_lda, lda_weight_strings[0], lda_weight_strings[1], c=y, s=(y+2)*10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A More Complicated Dataset, Faces\n",
    "This is code manipulated from Olivier Grisel's eigen face classification demonstration. You can find the original notebook here: http://nbviewer.ipython.org/github/ogrisel/notebooks/blob/master/Labeled%20Faces%20in%20the%20Wild%20recognition.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the images for the dataset\n",
    "# this will take a long time the first run because it needs to download\n",
    "# after the first time, the dataset will be save to your disk (in sklearn package somewhere) \n",
    "# if this does not run, you may need additional libraries installed on your system (install at your own risk!!)\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some of the specifics of the dataset\n",
    "X = lfw_people.data\n",
    "y = lfw_people.target\n",
    "names = lfw_people.target_names\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "_, h, w = lfw_people.images.shape\n",
    "n_classes = len(names)\n",
    "\n",
    "print(\"n_samples: {}\".format(n_samples))\n",
    "print(\"n_features: {}\".format(n_features))\n",
    "print(\"n_classes: {}\".format(n_classes))\n",
    "print(\"Original Image Sizes {}by{}\".format(h,w))\n",
    "print (50*37 )# the size of the images are the size of the feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So basically each feature vector is a giant image with the rows of the image just stacked one after the other into a giant vector. The image sizes are 50 pixels by 37 pixels. This gives us 50x37=1850 pixels per image.\n",
    "\n",
    "So we are using the pixel values in the images as the values of the features. Wow. That's a lot of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper plotting function\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=6):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.7 * n_col, 2.3 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "plot_gallery(X, names[y], h, w) # defaults to showing a 3 by 6 subset of the faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct Using Full PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets do some PCA of the features and go from 1850 features to 20 features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 300\n",
    "print (\"Extracting the top %d eigenfaces from %d faces\" % (\n",
    "    n_components, X.shape[0]))\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "%time pca.fit(X)\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
    "plot_gallery(eigenfaces, eigenface_titles, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_image(trans_obj,org_features,faces):\n",
    "    low_rep = trans_obj.transform(org_features)[0]\n",
    "    rec_image = np.zeros(faces[0].shape)\n",
    "\n",
    "    for idx,weight in enumerate(low_rep):\n",
    "        rec_image += weight*faces[idx]\n",
    "    return low_rep, rec_image\n",
    "    \n",
    "idx_to_reconstruct = 4    \n",
    "low_dimensional_representation, reconstructed_image = reconstruct_image(pca,X[idx_to_reconstruct],eigenfaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X[idx_to_reconstruct].reshape((h, w)), cmap=plt.cm.gray)\n",
    "plt.title('Original')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(reconstructed_image, cmap=plt.cm.gray)\n",
    "plt.title('Reconstructed from Full PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Let's Use Randomized PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets do some PCA of the features and go from 1850 features to 300 features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 300\n",
    "print (\"Extracting the top %d eigenfaces from %d faces\" % (\n",
    "    n_components, X.shape[0]))\n",
    "\n",
    "pca = PCA(n_components=n_components,svd_solver='randomized')\n",
    "%time pca.fit(X)\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
    "plot_gallery(eigenfaces, eigenface_titles, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay, so lets choose an image and reconstruct it using the eigenfaces\n",
    "from random import random as rd\n",
    "from ipywidgets import widgets  # make this interactive!\n",
    "\n",
    "def plt_reconstruct(idx_to_reconstruct):\n",
    "    idx_to_reconstruct = np.round(idx_to_reconstruct)\n",
    "    low_dimensional_representation, reconstructed_image = reconstruct_image(pca,X[idx_to_reconstruct],eigenfaces)\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(X[idx_to_reconstruct].reshape((h, w)), cmap=plt.cm.gray)\n",
    "    plt.title('Original')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(reconstructed_image, cmap=plt.cm.gray)\n",
    "    plt.title('Reconstructed')\n",
    "    \n",
    "widgets.interact(plt_reconstruct,idx_to_reconstruct=(1,100,1),__manual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
